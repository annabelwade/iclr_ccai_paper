@article{hms,
author = {McNamara, Donna and Stephens, George and Ruminski, Mark and Kasheta, Tim},
year = {2004},
month = {01},
title = {The Hazard Mapping System (HMS) - NOAA'S multi-sensor fire and smoke detection program using environmental satellites},
journal = {Conference on Satellite Meteorology and Oceanography}
}

@article{wildfire-risk,
author = {Marshall Burke  and Anne Driscoll  and Sam Heft-Neal  and Jiani Xue  and Jennifer Burney  and Michael Wara },
title = {The changing risk and burden of wildfire in the United States},
journal = {Proceedings of the National Academy of Sciences},
volume = {118},
number = {2},
pages = {e2011048118},
year = {2021},
doi = {10.1073/pnas.2011048118},
URL = {{https://www.pnas.org/doi/abs/10.1073/pnas.2011048118}},
abstract = {Recent dramatic and deadly increases in global wildfire activity have increased attention on the causes of wildfires, their consequences, and how risk from wildfire might be mitigated. Here we bring together data on the changing risk and societal burden of wildfire in the United States. We estimate that nearly 50 million homes are currently in the wildland–urban interface in the United States, a number increasing by 1 million houses every 3 y. To illustrate how changes in wildfire activity might affect air pollution and related health outcomes, and how these linkages might guide future science and policy, we develop a statistical model that relates satellite-based fire and smoke data to information from pollution monitoring stations. Using the model, we estimate that wildfires have accounted for up to 25\% of PM2.5 (particulate matter with diameter \&lt;2.5 μm) in recent years across the United States, and up to half in some Western regions, with spatial patterns in ambient smoke exposure that do not follow traditional socioeconomic pollution exposure gradients. We combine the model with stylized scenarios to show that fuel management interventions could have large health benefits and that future health impacts from climate-change–induced wildfire smoke could approach projected overall increases in temperature-related mortality from climate change—but that both estimates remain uncertain. We use model results to highlight important areas for future research and to draw lessons for policy.}}

@article{ensemble-diversity,
  author       = {Ludmila I. Kuncheva and Christopher J. Whitaker},
  title        = {Measures of Diversity in Classifier Ensembles and Their Relationship with the Ensemble Accuracy},
  journal      = {Machine Learning},
  year         = {2003},
  volume       = {51},
  number       = {2},
  pages        = {181--207},
  doi          = {10.1023/A:1022859003006},
  url          = {{https://doi.org/10.1023/A:1022859003006}},
  issn         = {1573-0565}
}

@article{nn-ensemble2,
author = {Cheng Ju, Aurélien Bibaut and Mark van der Laan},
title = {The relative performance of ensemble methods with deep convolutional neural networks for image classification},
journal = {Journal of Applied Statistics},
volume = {45},
number = {15},
pages = {2800--2818},
year = {2018},
publisher = {Taylor \& Francis},
doi = {10.1080/02664763.2018.1441383},
    note ={PMID: 31631918},
URL = {{https://doi.org/10.1080/02664763.2018.1441383}}
}

@article{nn-ensemble,
  author={Hansen, L.K. and Salamon, P.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Neural network ensembles}, 
  year={1990},
  volume={12},
  number={10},
  pages={993-1001},
  keywords={Neural networks;Databases;Fault tolerance;Supervised learning;Pattern recognition;Computer architecture;Neurons;Data mining;Feedforward systems;Performance analysis},
  doi={10.1109/34.58871}}

@article{ensemble-ml,
  author = {Dietterich, Thomas G.},
  title = {Ensemble Methods in Machine Learning},
  journal = {Multiple Classifier Systems},
  year = {2000},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  pages = {1--15},
  abstract = {Ensemble methods are learning algorithms that construct a set of classifiers and then classify new data points by taking a (weighted) vote of their predictions. The original ensemble method is Bayesian averaging, but more recent algorithms include error-correcting output coding, Bagging, and boosting. This paper reviews these methods and explains why ensembles can often perform better than any single classifier. Some previous studies comparing ensemble methods are reviewed, and some new experiments are presented to uncover the reasons that Adaboost does not overfit rapidly.},
  isbn = {978-3-540-45014-6}
}

@misc{dlv3p,
      title={Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation}, 
      author={Liang-Chieh Chen and Yukun Zhu and George Papandreou and Florian Schroff and Hartwig Adam},
      year={2018},
      eprint={1802.02611},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={{https://arxiv.org/abs/1802.02611}}
}

@article{PAN,
  author       = {Hanchao Li and
                  Pengfei Xiong and
                  Jie An and
                  Lingxue Wang},
  title        = {Pyramid Attention Network for Semantic Segmentation},
  journal      = {CoRR},
  volume       = {abs/1805.10180},
  year         = {2018},
  url          = {{http://arxiv.org/abs/1805.10180}},
  eprinttype    = {arXiv},
  eprint       = {1805.10180},
}

@book{GOESbook,
  author    = {S. J. Goodman and T. J. Schmit and J. Daniels and R. J. Redmon},
  title     = {The GOES-R Series: A New Generation of Geostationary Environmental Satellites},
  publisher = {Elsevier},
  year      = {2019}
}


@article{UNetpp,
  author       = {Zongwei Zhou and
                  Md Mahfuzur Rahman Siddiquee and
                  Nima Tajbakhsh and
                  Jianming Liang},
  title        = {UNet++: A Nested U-Net Architecture for Medical Image Segmentation},
  journal      = {CoRR},
  volume       = {abs/1807.10165},
  year         = {2018},
  url          = {{http://arxiv.org/abs/1807.10165}},
  eprinttype    = {arXiv},
  eprint       = {1807.10165},
  timestamp    = {Mon, 13 Aug 2018 16:46:03 +0200},
}

@misc{semantic,
  Author = {Pavel Iakubovskii},
  Title = {Segmentation Models Pytorch},
  Year = {2019},
  Publisher = {GitHub},
  howpublished = {\url{https://github.com/qubvel/segmentation_models.pytorch}}
}